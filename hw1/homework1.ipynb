{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jv6raPE04xmm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework 1 - Berkeley STAT 157\n",
    "\n",
    "Handout 1/22/2017, due 1/29/2017 by 4pm in Git by committing to your repository. Please ensure that you add the TA Git account to your repository.\n",
    "\n",
    "1. Write all code in the notebook.\n",
    "1. Write all text in the notebook. You can use MathJax to insert math or generic Markdown to insert figures (it's unlikely you'll need the latter). \n",
    "1. **Execute** the notebook and **save** the results.\n",
    "1. To be safe, print the notebook as PDF and add it to the repository, too. Your repository should contain two files: ``homework1.ipynb`` and ``homework1.pdf``. \n",
    "\n",
    "The TA will return the corrected and annotated homework back to you via Git (please give `rythei` access to your repository)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completed by Derek Topper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T19:57:47.188990Z",
     "start_time": "2019-01-22T19:57:46.107420Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Iapj_JTt4xmp"
   },
   "outputs": [],
   "source": [
    "from mxnet import ndarray as nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NEICVDod4xmu"
   },
   "source": [
    "## 1. Speedtest for vectorization\n",
    "\n",
    "Your goal is to measure the speed of linear algebra operations for different levels of vectorization. You need to use `wait_to_read()` on the output to ensure that the result is computed completely, since NDArray uses asynchronous computation. Please see http://beta.mxnet.io/api/ndarray/_autogen/mxnet.ndarray.NDArray.wait_to_read.html for details. \n",
    "\n",
    "1. Construct two matrices $A$ and $B$ with Gaussian random entries of size $4096 \\times 4096$. \n",
    "1. Compute $C = A B$ using matrix-matrix operations and report the time. \n",
    "1. Compute $C = A B$, treating $A$ as a matrix but computing the result for each column of $B$ one at a time. Report the time.\n",
    "1. Compute $C = A B$, treating $A$ and $B$ as collections of vectors. Report the time.\n",
    "1. Bonus question - what changes if you execute this on a GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCSkg_C_4xmv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Matrix A:  \n",
      "[[ 0.56771386  0.7645655   0.11443903 ... -0.36707944  0.6214844\n",
      "  -0.25809753]\n",
      " [-0.49916062 -1.4440985  -0.4240666  ...  1.9710336   1.2054701\n",
      "  -0.3057277 ]\n",
      " [ 1.9037348  -1.2539812   0.29832017 ... -1.8558106  -0.5498901\n",
      "  -2.0836408 ]\n",
      " ...\n",
      " [-0.40491968 -1.0990205  -0.20398566 ...  0.551011    0.7903397\n",
      "  -0.3774016 ]\n",
      " [ 0.30279776 -0.49025026 -0.46261027 ...  0.83185124  0.56484663\n",
      "   1.0392649 ]\n",
      " [ 2.6575677   1.1626844  -1.2029338  ... -0.28907916 -0.61258596\n",
      "   1.2751752 ]]\n",
      "<NDArray 4096x4096 @cpu(0)>\n",
      "1. Matrix B:  \n",
      "[[-1.442437    0.9651673   0.56613606 ...  1.5337075   0.79065764\n",
      "  -0.35848466]\n",
      " [ 0.6879258  -1.0146283  -1.1928986  ...  0.16327435 -0.27324632\n",
      "   0.2036404 ]\n",
      " [-0.5992413  -0.6638654   0.41060147 ... -0.40307128  0.18503273\n",
      "   0.02919667]\n",
      " ...\n",
      " [-0.8979426  -0.10159507 -0.58966035 ...  0.89585197  0.12146354\n",
      "  -0.07107061]\n",
      " [-0.8536866   2.0668826   0.3119022  ... -0.20358665 -0.0587807\n",
      "  -0.04785731]\n",
      " [-1.8013732  -1.9592597   0.41525716 ...  0.25073144  0.95281583\n",
      "   0.31331718]]\n",
      "<NDArray 4096x4096 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "import numpy as np\n",
    "A = nd.random.normal(0, 1, shape = (4096, 4096))\n",
    "B = nd.random.normal(0, 1, shape = (4096, 4096))\n",
    "print(\"1. Matrix A: \", A)\n",
    "print(\"1. Matrix B: \", B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iQbrgt94xmz",
    "outputId": "cad97d64-8140-4670-d73c-0e94fd5051d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for Part 2:  3.4846460819244385\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "C = nd.dot(A, B)\n",
    "C.wait_to_read()\n",
    "print(\"Time for Part 2: \", time.time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPNEtMsc4xm4",
    "outputId": "9d45819e-aef8-48fd-db01-d0431f85af35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for Part 3:  133.61406064033508\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "C = nd.empty((4096,4096))\n",
    "for each in np.arange(4096):\n",
    "    C[:,each] = nd.dot(A, B[:,each])\n",
    "C.wait_to_read()\n",
    "print(\"Time for Part 3: \", time.time() - tic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RoSTprIf4xm-",
    "outputId": "08fd1e09-300e-4943-9bbc-519831c08286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for Part 4:  31512.04070663452\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "C = nd.empty((4096,4096))\n",
    "for each in np.arange(4096):\n",
    "    for each2 in np.arange(4096):\n",
    "        C[each,each2] = nd.dot(A[each,:], B[:,each2])\n",
    "C.wait_to_read()\n",
    "print(\"Time for Part 4: \", time.time() - tic) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTyXEZmq4xnF"
   },
   "source": [
    "###### 5. It gets faster on GPU. A GPU accelerates the speed of computing, which would benefit us in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WiMr8kmZ4xnG"
   },
   "source": [
    "## 2. Semidefinite Matrices\n",
    "\n",
    "Assume that $A \\in \\mathbb{R}^{m \\times n}$ is an arbitrary matrix and that $D \\in \\mathbb{R}^{n \\times n}$ is a diagonal matrix with nonnegative entries. \n",
    "\n",
    "1. Prove that $B = A D A^\\top$ is a positive semidefinite matrix. \n",
    "1. When would it be useful to work with $B$ and when is it better to use $A$ and $D$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tsFLFuKx4xnH"
   },
   "source": [
    "#### ANSWER:\n",
    " \n",
    "1) \n",
    "If $B = ADA^\\top$ is a positive semidefinite matrix, then we need to make sure one of two things is occuring. Either the diagonal entries of the matrix are nonnegative or the $A^\\top DA$ is nonnegative. \n",
    "\n",
    "So we can say $x ^\\top A^\\top DAx = (Ax) D (Ax)^\\top$. \n",
    "\n",
    "Since D is assumed to have nonnegative entries, this can drop to zero only when Ax = 0. \n",
    "\n",
    "Since A is assumed to have independent columns, Ax = 0 only happens when x = 0. Thus $A^\\top D A$ is positive and is positive definite.\n",
    "\n",
    "Additionally, another way to prove this, is that we could alter $ADA^\\top$ to its vector form as $\\sum A_{i}^\\top D_{i} A_{i}$, which we know has to be nonnegative. Then We then could change that term to be $\\sum A_{i}^{2} D_{i}$, since $A^{2}$ must be nonnegative. Knowing this and combining it with the fact that D has nonneagtive entries, we know that $\\sum A_{i}^{2} D_{i}$ must be greater or equal to zero and thus $B = ADA^\\top$ is positive semidefinite as well.\n",
    "\n",
    "2) It would be useful to work with B much of the time. When we want to do a problem using every value in a matrix, then we use the real, full matrix. But, since we know B is diagonzable and symmetric, we can preform eigendecomposition on it, as shown earlier. \n",
    "\n",
    "However, decomposing a matrix, in terms of its eigenvalues (D) and its eigenvectors (A and $A^\\top$) lets us do certain matrix calculations, like computing the power of the matrix, easier and faster when we use the eigendecomposition of the matrix. This can help eliminate inefficiencies and redundancies, over just using B for something. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TaQtgMLJ4xnK"
   },
   "source": [
    "## 3. MXNet on GPUs\n",
    "\n",
    "1. Install GPU drivers (if needed)\n",
    "1. Install MXNet on a GPU instance\n",
    "1. Display `!nvidia-smi`\n",
    "1. Create a $2 \\times 2$ matrix on the GPU and print it. See http://d2l.ai/chapter_deep-learning-computation/use-gpu.html for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "NhW0XfGC5qO-",
    "outputId": "f11dabdb-498e-4a79-b2f6-6d7286c7e7fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 29 09:18:06 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   65C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "9imR4t6x5tEd",
    "outputId": "0f4b1305-d06d-45f4-9ab4-478e4fea34c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[2.2122064 0.7740038]\n",
       " [1.0434403 1.1839255]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import ndarray as nd\n",
    "x = nd.random.normal(0, 1, shape = (2, 2))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was done in Google Colab, using their GPU software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1856
    },
    "colab_type": "code",
    "id": "8gUWuJr_4xnM",
    "outputId": "6a2fa896-7e1b-4bba-f3ea-82137afe9279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet-cu92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/18/b4d7a80ee371bc18ac08e1714402a281af806e09aba108a10f6590720fff/mxnet_cu92-1.3.1-py2.py3-none-manylinux1_x86_64.whl (412.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 412.1MB 49kB/s \n",
      "tcmalloc: large alloc 1073750016 bytes == 0x5be6e000 @  0x7f72355362a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu92) (1.14.6)\n",
      "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet-cu92)\n",
      "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
      "Collecting requests>=2.20.0 (from mxnet-cu92)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 19.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu92) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu92) (1.22)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu92) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu92) (3.0.4)\n",
      "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-colab 0.0.1a1 has requirement requests~=2.18.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
      "Installing collected packages: graphviz, requests, mxnet-cu92\n",
      "  Found existing installation: graphviz 0.10.1\n",
      "    Uninstalling graphviz-0.10.1:\n",
      "      Successfully uninstalled graphviz-0.10.1\n",
      "  Found existing installation: requests 2.18.4\n",
      "    Uninstalling requests-2.18.4:\n",
      "      Successfully uninstalled requests-2.18.4\n",
      "Successfully installed graphviz-0.8.4 mxnet-cu92-1.3.1 requests-2.21.0\n",
      "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
      "  [requests]\n",
      "You must restart the runtime in order to use newly installed versions.\u001b[0m\n",
      "Collecting d2l\n",
      "  Downloading https://files.pythonhosted.org/packages/40/2b/618811a6331dc0cbb5d9731959f0c2b1b63bc1297c24401a3d7076e05624/d2l-0.8.7.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from d2l) (1.14.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from d2l) (3.0.2)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from d2l) (1.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (2.5.3)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (6.0.0)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (5.2.2)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (5.4.0)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (4.4.3)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (7.4.2)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (4.6.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->d2l) (40.6.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->d2l) (1.11.0)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l) (5.2.4)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l) (5.5.0)\n",
      "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->d2l)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/c2/e676da701cda11b32ff42eceb44aa7d8934b597d604bb5e94c0283def064/prompt_toolkit-2.0.8-py3-none-any.whl (342kB)\n",
      "\u001b[K    100% |████████████████████████████████| 348kB 7.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l) (2.1.3)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (4.4.0)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (4.3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (2.10)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (0.2.0)\n",
      "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (4.5.3)\n",
      "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (0.8.1)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (4.4.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.8.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.4.2)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.5.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (3.1.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (1.4.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l) (3.4.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->d2l) (17.0.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->d2l) (4.3.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->d2l) (0.8.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->d2l) (0.7.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->d2l) (4.6.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->d2l) (0.1.7)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->jupyter->d2l) (2.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter->d2l) (1.1.0)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->d2l) (0.6.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l) (0.5.1)\n",
      "Building wheels for collected packages: d2l\n",
      "  Running setup.py bdist_wheel for d2l ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c7/87/29/22170afbd70e10df77be0339d4e5863f452faa4a2f37ed979f\n",
      "Successfully built d2l\n",
      "\u001b[31mipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.8 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-colab 0.0.1a1 has requirement requests~=2.18.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
      "Installing collected packages: d2l, prompt-toolkit\n",
      "  Found existing installation: prompt-toolkit 1.0.15\n",
      "    Uninstalling prompt-toolkit-1.0.15:\n",
      "      Successfully uninstalled prompt-toolkit-1.0.15\n",
      "Successfully installed d2l-0.8.7 prompt-toolkit-2.0.8\n",
      "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
      "  [prompt_toolkit]\n",
      "You must restart the runtime in order to use newly installed versions.\u001b[0m\n",
      "Tue Jan 29 09:15:42 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   67C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet-cu92 #To Make Google Colab Work\n",
    "!pip install d2l\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GCR8Oat4xnP"
   },
   "source": [
    "## 4. NDArray and NumPy \n",
    "\n",
    "Your goal is to measure the speed penalty between MXNet Gluon and Python when converting data between both. We are going to do this as follows:\n",
    "\n",
    "1. Create two Gaussian random matrices $A, B$ of size $4096 \\times 4096$ in NDArray. \n",
    "1. Compute a vector $\\mathbf{c} \\in \\mathbb{R}^{4096}$ where $c_i = \\|A B_{i\\cdot}\\|^2$ where $\\mathbf{c}$ is a **NumPy** vector.\n",
    "\n",
    "To see the difference in speed due to Python perform the following two experiments and measure the time:\n",
    "\n",
    "1. Compute $\\|A B_{i\\cdot}\\|^2$ one at a time and assign its outcome to $\\mathbf{c}_i$ directly.\n",
    "1. Use an intermediate storage vector $\\mathbf{d}$ in NDArray for assignments and copy to NumPy at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1sPsvYZ4xnR"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "import numpy as np\n",
    "A = nd.random.normal(0, 1, shape = (4096, 4096))\n",
    "B = nd.random.normal(0, 1, shape = (4096, 4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Direct to NPArray:  136.09623432159424\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "C = np.zeros(4096)\n",
    "\n",
    "for each in range(4096):\n",
    "    C[each] = (nd.dot(A, B[:, each]).norm()**2).asscalar()\n",
    "\n",
    "print(\"1: Direct to NPArray: \", time.time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: NDArray Storage:  129.683664560318\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "d = nd.empty(4096)\n",
    "for each in np.arange(4096):\n",
    "    nd.norm(nd.dot(A, B[:,each]), out=d[each]**2)\n",
    "    #d[each] = d[each]**2\n",
    "d.wait_to_read()\n",
    "C = d.asnumpy()\n",
    "print(\"2: NDArray Storage: \", time.time() - tic) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgG9kvq34xnV"
   },
   "source": [
    "## 5. Memory efficient computation\n",
    "\n",
    "We want to compute $C \\leftarrow A \\cdot B + C$, where $A, B$ and $C$ are all matrices. Implement this in the most memory efficient manner. Pay attention to the following two things:\n",
    "\n",
    "1. Do not allocate new memory for the new value of $C$.\n",
    "1. Do not allocate new memory for intermediate results if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbeKKQqC4xnW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 56.  63.  70.  77.]\n",
       " [156. 179. 202. 225.]\n",
       " [256. 295. 334. 373.]\n",
       " [356. 411. 466. 521.]]\n",
       "<NDArray 4x4 @cpu(0)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = nd.arange(16).reshape(4,4)\n",
    "B = nd.arange(16).reshape(4,4)\n",
    "C = nd.arange(16).reshape(4,4)\n",
    "\n",
    "nd.elemwise_add(nd.dot(A,B), C, out=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This meets the criteria outlined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S53mamDh4xna"
   },
   "source": [
    "## 6. Broadcast Operations\n",
    "\n",
    "In order to perform polynomial fitting we want to compute a design matrix $A$ with \n",
    "\n",
    "$$A_{ij} = x_i^j$$\n",
    "\n",
    "Our goal is to implement this **without a single for loop** entirely using vectorization and broadcast. Here $1 \\leq j \\leq 20$ and $x = \\{-10, -9.9, \\ldots 10\\}$. Implement code that generates such a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S02RUxMN4xnc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.00000000e+01,  1.00000000e+02, -1.00000000e+03, ...,\n",
       "         1.00000000e+18, -1.00000000e+19,  1.00000000e+20],\n",
       "       [-9.90000000e+00,  9.80100000e+01, -9.70299000e+02, ...,\n",
       "         8.34513761e+17, -8.26168624e+18,  8.17906938e+19],\n",
       "       [-9.80000000e+00,  9.60400000e+01, -9.41192000e+02, ...,\n",
       "         6.95135331e+17, -6.81232624e+18,  6.67607972e+19],\n",
       "       ...,\n",
       "       [ 9.80000000e+00,  9.60400000e+01,  9.41192000e+02, ...,\n",
       "         6.95135331e+17,  6.81232624e+18,  6.67607972e+19],\n",
       "       [ 9.90000000e+00,  9.80100000e+01,  9.70299000e+02, ...,\n",
       "         8.34513761e+17,  8.26168624e+18,  8.17906938e+19],\n",
       "       [ 1.00000000e+01,  1.00000000e+02,  1.00000000e+03, ...,\n",
       "         1.00000000e+18,  1.00000000e+19,  1.00000000e+20]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = np.arange(1,21)\n",
    "x = np.arange(-10, 10.1, .1)\n",
    "x[:, np.newaxis]**j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "homework1 (2).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
